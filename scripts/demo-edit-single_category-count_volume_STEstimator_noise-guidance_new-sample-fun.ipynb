{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83815b2-5e5a-4a0e-ad9f-7b2f0b09788b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install lab_black\n",
    "#%load_ext lab_black\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89b5d-ac8f-49a1-80ed-3be17153192a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "from src.utils import instantiate_from_config, get_device\n",
    "from src.utils.vis import save_sdf_as_mesh, plot_sdfs\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ae8df-0703-4eed-94e8-0c75126d7118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "th.set_grad_enabled(False)\n",
    "device = get_device()\n",
    "#device=\"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ab22a-d774-490f-980a-6e310bae128c",
   "metadata": {},
   "source": [
    "# Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1928db-db77-4b88-b36f-8613a810399e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen32_args_path = \"config/gen32/chair.yaml\"\n",
    "gen32_ckpt_path = \"results/gen32/chair.pth\"\n",
    "sr64_args_path = \"config/sr32_64/chair.yaml\"\n",
    "sr64_ckpt_path = \"results/sr32_64/chair.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcebfec-8f2b-42ae-9a55-e8517bee8cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(gen32_args_path) as f:\n",
    "    args1 = EasyDict(yaml.safe_load(f))\n",
    "with open(sr64_args_path) as f:\n",
    "    args2 = EasyDict(yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75f0c2-b8fe-4d80-8797-894a6d077f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = instantiate_from_config(args1.model)\n",
    "ckpt = th.load(gen32_ckpt_path, map_location=device)\n",
    "model1.load_state_dict(ckpt[\"model_ema\"])\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "model1.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f4dbd-6fca-409e-bbef-e85f7a066b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = instantiate_from_config(args2.model)\n",
    "ckpt = th.load(sr64_ckpt_path, map_location=device)\n",
    "model2.load_state_dict(ckpt[\"model\"])\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "model2.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efd984-8e93-4041-84cf-d70b3cd64bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.models.gaussian_diffusion import create_gaussian_diffusion\n",
    "noise_level_func = \"sqrt_alphas_cumprod_next\"\n",
    "ddpm_sampler1 = create_gaussian_diffusion(noise_level_func=noise_level_func, **args1.ddpm_new.valid.params)\n",
    "ddpm_sampler2 = create_gaussian_diffusion(noise_level_func=noise_level_func, **args2.ddpm_new.valid.params)\n",
    "\n",
    "#ddpm_sampler1, ddpm_sampler2 = ddpm_sampler1.to(device), ddpm_sampler2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e87cc-6e85-4cc7-b41e-beac554f1d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor1 = instantiate_from_config(args1.preprocessor, device=device)\n",
    "preprocessor2 = instantiate_from_config(args2.preprocessor, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c31d13-c9b5-42b3-bf7e-6819aee68b44",
   "metadata": {},
   "source": [
    "# Generate Low-Resolution ($32^3$)\n",
    "\n",
    "Generates 5 low-resolution samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91830712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import seed_everything\n",
    "seed_everything(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e759bd-f309-48e5-8c1e-e7b8fb0dfa2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out1 = ddpm_sampler1.ddim_sample_loop(model1, shape=(2, 1, 32, 32, 32), progress=True, device=device)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fceb1e-d513-40b5-8954-e766fb82808a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out1 = preprocessor1.destandardize(out1)\n",
    "print(out1.mean(), out1.min(), out1.max(), out1.var())\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbffe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1_std = preprocessor1.standardize(out1)\n",
    "print(out1_std.mean(), out1_std.min(), out1_std.max(), out1_std.var())\n",
    "out1_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036976bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.vis import plot_sdfs\n",
    "view_kwargs = {\"azim\": 30, \"elev\": 30, \"roll\": 0, \"vertical_axis\": \"y\"}\n",
    "plot_sdfs(list(out1), view_kwargs=view_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.gaussian_diffusion import create_gaussian_diffusion\n",
    "noise_level_func = \"sqrt_alphas_cumprod_next\"\n",
    "ddpm_sampler1 = create_gaussian_diffusion(noise_level_func=noise_level_func, sigma_small=True, **args1.ddpm_new.valid.params)\n",
    "ddpm_sampler2 = create_gaussian_diffusion(noise_level_func=noise_level_func, sigma_small=True, **args2.ddpm_new.valid.params)\n",
    "\n",
    "from src.utils.vis import plot_sdfs\n",
    "def plot_debug_func(x, iter, every_t=20, **plot_sdfs_kwargs):\n",
    "    if iter % every_t == 0 or iter == len(ddpm_sampler1.use_timesteps)-1:\n",
    "        title = f\"iter: {iter} / {len(ddpm_sampler1.use_timesteps)}\"\n",
    "        plot_sdfs(x, title=title, **plot_sdfs_kwargs)\n",
    "\n",
    "out1 = ddpm_sampler1.ddim_sample_loop(model1, shape=(3, 1, 32, 32, 32), progress=True, plot_debug_func=plot_debug_func, device=device)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52108c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = preprocessor1.destandardize(out1)\n",
    "print(out1.mean(), out1.min(), out1.max(), out1.var())\n",
    "#out1.shape\n",
    "out1_std = preprocessor1.standardize(out1)\n",
    "print(out1_std.mean(), out1_std.min(), out1_std.max(), out1_std.var())\n",
    "#out1_std.shape\n",
    "from src.utils.vis import plot_sdfs\n",
    "view_kwargs = {\"azim\": 30, \"elev\": 30, \"roll\": 0, \"vertical_axis\": \"y\"}\n",
    "plot_sdfs(list(out1), view_kwargs=view_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997dc3e6-1c88-4245-9bfb-909d8247c016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save as an obj file\n",
    "# for i, out in enumerate(out1):\n",
    "#     save_sdf_as_mesh(f\"gen32_{i}.obj\", out, safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f373ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cond = F.interpolate(out1, (64, 64, 64), mode=\"nearest\")\n",
    "lr_cond = preprocessor2.standardize(lr_cond, 0)\n",
    "out2 = ddpm_sampler1.ddim_sample_loop(lambda x, t: model2(th.cat([lr_cond, x], 1), t), shape=(out1.shape[0], 1, 64, 64, 64), progress=True, device=device)\n",
    "\n",
    "out2 = preprocessor2.destandardize(out2, 1)\n",
    "\n",
    "#for i, out in enumerate(out2):\n",
    "#    save_sdf_as_mesh(f\"sr64_{i}.obj\", out, safe=True)\n",
    "\n",
    "plot_sdfs(list(out2), title=\"Super-resolution origianal samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization \n",
    "def volume_estimates(sdfs, dx=1., dy=1., dz=1.): \n",
    "    #inside_mask = (-sdfs) > 0\n",
    "    #volume_estimates = th.sum(inside_mask.float(), dim=list(range(1, sdfs.ndim)))\n",
    "    volume_estimates_activation = th.sum(StraightThroughEstimator()(-sdfs), dim=list(range(1, sdfs.ndim)))\n",
    "    #assert th.allclose(volume_estimates, volume_estimates_bin_activation), f\"using mask: {volume_estimates}, with activation function {volume_estimates_bin_activation}\"\n",
    "    return volume_estimates_activation * dx * dy * dz\n",
    "\n",
    "class STEFunction(th.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return (input > 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return F.hardtanh(grad_output)\n",
    "\n",
    "class StraightThroughEstimator(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StraightThroughEstimator, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = STEFunction.apply(x)\n",
    "        return x\n",
    " \n",
    "\n",
    "def volume_estimates_loss_fn(xs, target_volumes, max_volume=1., grad_var_reg_weight=0, tot_variation_reg_weight=0):\n",
    "    input_volumes = volume_estimates(xs) / max_volume\n",
    "    target_volumes = target_volumes / max_volume\n",
    "    loss = th.nn.MSELoss()(input_volumes, target_volumes)\n",
    "    if grad_var_reg_weight > 0:\n",
    "        loss += grad_var_reg_weight * th.var(xs.grad, dim=list(range(1, xs.ndim)))\n",
    "    if tot_variation_reg_weight > 0:\n",
    "        loss += tot_variation_reg_weight * tot_variation(xs)\n",
    "    return loss \n",
    "\n",
    "def simple_loss(xs, target_volumes=0., max_volume=1., grad_var_reg_weight=0, tot_variation_reg_weight=0):\n",
    "    loss = th.nn.MSELoss()(-xs.sum(dim=list(range(1, xs.ndim))), target_volumes)\n",
    "    return loss\n",
    "\n",
    "def tot_variation(sdfs, weight=1.):       \n",
    "    tv_x = ((sdfs[:,:,1:,:,:] - sdfs[:,:,:-1,:,:]).pow(2)).sum()\n",
    "    tv_y = ((sdfs[:,:,:,1:,:] - sdfs[:,:,:,:-1,:]).pow(2)).sum()    \n",
    "    tv_z = ((sdfs[:,:,:,:,1:] - sdfs[:,:,:,:,:-1]).pow(2)).sum()\n",
    "    return tv_x + tv_y + tv_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.utils import identity\n",
    "def ddim_sample_noise_guidance(\n",
    "    diffusion,\n",
    "    denoise_fn,\n",
    "    x_0,\n",
    "    from_t_optim_idx,\n",
    "    obj_fn,\n",
    "    obj_fn_args={},\n",
    "    tgt_noise_level = \"t_optim\",\n",
    "    clip_denoised=True,\n",
    "    denoise_kwargs={},\n",
    "    post_fn=identity,\n",
    "    #return_intermediates=False,\n",
    "    log_every_t=5,\n",
    "    show_pbar=False,\n",
    "    pbar_kwargs={},\n",
    "    opt_kwargs={\"lr\":1e-2, \"decay_fn\": identity}, \n",
    "    grad_clip_value=None,\n",
    "    plot_debug=False,\n",
    "):        \n",
    "    ddim_args = {\n",
    "        \"clip_denoised\": clip_denoised,\n",
    "        \"denoise_kwargs\": denoise_kwargs, \n",
    "        \"post_fn\": post_fn, \n",
    "        #\"return_intermediates\": return_intermediates, \n",
    "        \"log_every_t\": log_every_t, \n",
    "        \"show_pbar\": show_pbar, \n",
    "        \"pbar_kwargs\": pbar_kwargs\n",
    "    }\n",
    "\n",
    "    timesteps = sorted(list(diffusion.use_timesteps))\n",
    "\n",
    "    # Get the latent at the defined noise level\n",
    "    x_t = diffusion.ddim_sample_loop(model=denoise_fn, x_t=x_0, inverse=True, to_t_idx=from_t_optim_idx, requires_grad=False)\n",
    "    if plot_debug:  \n",
    "        plot_sdfs(x_t, title=f\"x_t inverted to timestep {timesteps[from_t_optim_idx]}\")\n",
    "\n",
    "    # Denoise it with guidance\n",
    "    # if from_t_optim_idx < 0:\n",
    "    #     idxs = range(from_t_optim_idx, 0)\n",
    "    # else:\n",
    "    #     idxs = range(from_t_optim_idx, len(self.ddim_timesteps))\n",
    "    idxs = range(from_t_optim_idx, 0, -1)\n",
    "    \n",
    "    # x_t_optim = x_t.clone()\n",
    "    # x_t_optim.requires_grad = True\n",
    "    #optimizer = th.optim.AdamW([x_t_optim], **opt_kwargs)\n",
    "    with tqdm(idxs, desc=\"Latent optimization\") as pbar_idxs:\n",
    "        for i, t_idx in enumerate(pbar_idxs):\n",
    "            #x_t_optim = x_t.clone().detach()\n",
    "            x_t_optim = x_t.detach()\n",
    "            x_t_optim.requires_grad_(True)\n",
    "            if tgt_noise_level == \"t_optim\":\n",
    "                tgt_pred = x_t_optim\n",
    "            elif tgt_noise_level == \"zero\":\n",
    "                # with th.enable_grad():\n",
    "                #     tgt_pred = diffusion.ddim_sample_loop(model=denoise_fn, x_t=x_t_optim, from_t_idx=t_idx)\n",
    "                tgt_pred = diffusion.ddim_sample_loop(model=denoise_fn, x_t=x_t_optim, from_t_idx=t_idx, requires_grad=True) \n",
    "            elif tgt_noise_level == \"zero_pred\": \n",
    "                with th.enable_grad():\n",
    "                    tgt_pred = diffusion.ddim_sample(model=denoise_fn, x=x_t_optim, t=th.tensor([t_idx] * x_0.shape[0], device=device))[\"pred_xstart\"]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid noise level: available levels are \" + [\"t_optim\", \"zero\", \"zero_pred\"] + \".\")\n",
    "            \n",
    "            # loss_i = obj_fn(tgt_pred, **obj_fn_args)\n",
    "            # #tgt_pred.requires_grad_(True)\n",
    "            # optimizer.zero_grad()\n",
    "            # loss_i.backward()\n",
    "            # # if grad_clip_value is not None:\n",
    "            # #     th.nn.utils.clip_grad_value_(x_t, grad_clip_value)\n",
    "            # optimizer.step()\n",
    "\n",
    "            \n",
    "            with th.enable_grad():\n",
    "                loss_i = obj_fn(tgt_pred, **obj_fn_args) # tgt_pred is a function of x_t\n",
    "                grad_t = th.autograd.grad(loss_i, x_t_optim, retain_graph=False)[0] # grad of loss wrt to x_t\n",
    "            print(\"Grad. norm: \", th.norm(grad_t).item(), \" vs x_t norm: \", th.norm(x_t).item())\n",
    "\n",
    "            # x_{t} optimized \n",
    "            decay_fn = opt_kwargs.get(\"decay_fn\", identity)\n",
    "            x_t = x_t - decay_fn(i) * opt_kwargs[\"lr\"] * grad_t\n",
    "            x_t.grad = x_t_optim.grad = loss_i.grad = tgt_pred.grad = None\n",
    "\n",
    "            pbar_idxs.set_postfix({\"Loss (mean)\": th.mean(loss_i).item()})\n",
    "\n",
    "            if plot_debug:\n",
    "                plot_sdfs([tgt_pred, x_t], title=f\"Optimization step {i} at timestep {timesteps[t_idx]}\", titles=[f\"Target shape (target type: \\\"{tgt_noise_level}\\\")\", f\"Optimized shape\"]) #(V={th.sum(x_t<0, dim=list(range(1, len(x_t.shape)))).item()})\"])\n",
    "\n",
    "            # x_{t-1} \n",
    "            x_t = diffusion.ddim_sample(model=denoise_fn, x=x_t.detach(), t=th.tensor([t_idx] * x_0.shape[0], device=device, requires_grad=False))[\"sample\"]\n",
    "            # x_t = self.sample_ddim(denoise_fn, x_t=x_t, from_t_idx=-(t_idx), to_t_idx=-(t_idx-1), requires_grad=False, **ddim_args) # x_{t-1}\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = -0.061\n",
    "plot_sdfs(\n",
    "    [out1, out1 + shift], \n",
    "    titles=[\n",
    "        [f\"Original \\n $V={volume_estimates(out_i).item()}$\" for out_i in out1], \n",
    "        [f\"Shifting the sdfs by ${shift}$ \\n $V={volume_estimates(out_i_shift).item()}$ (incr.: ${((volume_estimates(out_i_shift).item() - volume_estimates(out_i).item())/volume_estimates(out_i).item()):.2f}$)\" for out_i_shift, out_i in zip(out1+shift, out1)], \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.1, 1.4, 1.7], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=True,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f360c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.1, 1.4, 1.7], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=True,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.1, 1.4, 1.7], device=device)\n",
    "t_optim_idx = 25\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cdeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c43d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.1, 1.4, 1.7], device=device)\n",
    "t_optim_idx = 4\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std[0:1], \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std[0:1]) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=True,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1[0:1], \n",
    "        preprocessor1.destandardize(x_edited[0:1]), \n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at $t=0$\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1[0:1].shape[0])], \n",
    "        [f\"Edited ($V_{{edit}} = {volume_estimates(x_edited)[i].item():.2f}, V_{{target}}= {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1[0:1].shape[0])],\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = -0.062\n",
    "plot_sdfs(\n",
    "    [out1, out1 + shift], \n",
    "    titles=[\n",
    "        [f\"Original \\n $V={volume_estimates(out_i).item()}$\" for out_i in out1], \n",
    "        [f\"Shifting the sdfs by ${shift}$ \\n $V={volume_estimates(out_i_shift).item()}$ (incr.: ${((volume_estimates(out_i_shift).item() - volume_estimates(out_i).item())/volume_estimates(out_i).item()):.2f}$)\" for out_i_shift, out_i in zip(out1+shift, out1)], \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ccf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.3, 1.7, 2.1], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.3, 1.7, 2.1], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71958716",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([1.3, 1.7, 2.1], device=device)\n",
    "t_optim_idx = 4\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std[0:1], \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std[0:1]) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=True,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1[0:1], \n",
    "        preprocessor1.destandardize(x_edited[0:1]), \n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at $t=0$\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1[0:1].shape[0])], \n",
    "        [f\"Edited ($V_{{edit}} = {volume_estimates(x_edited)[i].item():.2f}, V_{{target}}= {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1[0:1].shape[0])],\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8606828",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = +0.02\n",
    "plot_sdfs(\n",
    "    [out1, out1 + shift], \n",
    "    titles=[\n",
    "        [f\"Original \\n $V={volume_estimates(out_i).item()}$\" for out_i in out1], \n",
    "        [f\"Shifting the sdfs by ${shift}$ \\n $V={volume_estimates(out_i_shift).item()}$ (incr.: ${((volume_estimates(out_i_shift).item() - volume_estimates(out_i).item())/volume_estimates(out_i).item()):.2f}$)\" for out_i_shift, out_i in zip(out1+shift, out1)], \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.3, -0.35, -0.32], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fead75",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.3, -0.35, -0.32], device=device)\n",
    "t_optim_idx = 25\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc76cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.3, -0.35, -0.32], device=device)\n",
    "t_optim_idx = 35\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0411ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.3, -0.35, -0.32], device=device)\n",
    "t_optim_idx = 35\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":.5e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.3, -0.35, -0.32], device=device)\n",
    "t_optim_idx = 20\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = +0.04\n",
    "plot_sdfs(\n",
    "    [out1, out1 + shift], \n",
    "    titles=[\n",
    "        [f\"Original \\n $V={volume_estimates(out_i).item()}$\" for out_i in out1], \n",
    "        [f\"Shifting the sdfs by ${shift}$ \\n $V={volume_estimates(out_i_shift).item()}$ (incr.: ${((volume_estimates(out_i_shift).item() - volume_estimates(out_i).item())/volume_estimates(out_i).item()):.2f}$)\" for out_i_shift, out_i in zip(out1+shift, out1)], \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 20\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28627e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 20\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments)},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 30\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf96174",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 10\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f52561",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 12\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 10\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"t_optim\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the same timestep\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 15\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":.5e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 30\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a38236",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 20\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.,\n",
    "        \"tot_variation_reg_weight\": 1e-1},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 30\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":1e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increments = th.tensor([-0.55, -0.6, -0.65], device=device)\n",
    "t_optim_idx = 30\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increments),\n",
    "        \"max_volume\": 1.,\n",
    "        \"tot_variation_reg_weight\": 1e-2},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero_pred\",\n",
    "    opt_kwargs={\"lr\":.5e-3}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the PREDICTED volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increments[i]):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_volume_increment = -0.58\n",
    "t_optim_idx = 5\n",
    "x_edited = ddim_sample_noise_guidance(\n",
    "    ddpm_sampler1,\n",
    "    model1, \n",
    "    x_0=out1_std, \n",
    "    obj_fn=volume_estimates_loss_fn, \n",
    "    obj_fn_args={\n",
    "        \"target_volumes\": volume_estimates(out1_std) * (1+target_volume_increment),\n",
    "        \"max_volume\": 1.},\n",
    "    from_t_optim_idx=t_optim_idx, \n",
    "    tgt_noise_level=\"zero\",\n",
    "    opt_kwargs={\"lr\":1e-2}, \n",
    "    plot_debug=False,\n",
    ")\n",
    "\n",
    "#plot_sdfs(sdfs=[x_t, x_t_optim], title=f\"Latent at $t={ddpm_sampler1.ddim_timesteps[t_optim_idx]}$\", titles=[\"Latent to be optimized\", \"Optimized latent\"]) \n",
    "\n",
    "plot_sdfs(\n",
    "    sdfs=[\n",
    "        out1, \n",
    "        preprocessor1.destandardize(x_edited), \n",
    "        #th.abs(out1- preprocessor1.destandardize(x_edited))\n",
    "    ], \n",
    "    title = f\"Optimization from the latent at $t={sorted(list(ddpm_sampler1.use_timesteps))[t_optim_idx]}$ based on the volume at the timestep 0\",\n",
    "    titles=[\n",
    "        [f\"Original ($V = {volume_estimates(out1_std)[i].item():.2f}$)\" for i in range(out1.shape[0])], \n",
    "        [f\"Edited ($V_E = {volume_estimates(x_edited)[i].item():.2f} - V_{{target}}: {volume_estimates(out1_std)[i].item() * (1+target_volume_increment):.2f})$\" for i in range(out1.shape[0])],\n",
    "        #[f\"Absolute difference between original and edited\" for i in range(out1.shape[0])]\n",
    "        ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
